# 360Â° Feedback on Government of Indiaâ€“Related News in Regional Media (AI/ML)

> A multilingual, privacyâ€‘aware pipeline that ingests regional news, extracts insights about Government of India (GoI) entities, and delivers 360â€‘degree feedback loops for policymakers, departments, and the public.

---

## ğŸš€ TL;DR

* **Goal:** Build an endâ€‘toâ€‘end system to monitor regional media, detect stories about GoI ministries/schemes/officials, and summarize public sentiment, narratives, and emerging issuesâ€”then route insights as actionable feedback to stakeholders.
* **Why it matters:** Policy and service delivery benefit when decisionâ€‘makers hear from all directionsâ€”media, citizens, and internal teamsâ€”especially across Indiaâ€™s many languages.
* **How:** Crawling â†’ Clean/Deâ€‘dupe â†’ Multilingual NLP (NER, sentiment, stance, topic, clustering) â†’ Summaries & KPIs â†’ Dashboards & alerts â†’ Feedback capture â†’ Continuous learning.

---

## ğŸ¯ Objectives

1. **Comprehensive Coverage:** Track GoIâ€‘related stories across **regional languages** and sources (print eâ€‘papers, TV transcripts when available, local portals, verified social mentions).
2. **Entity Awareness:** Identify **ministries, departments, schemes (e.g., PMâ€‘KISAN), offices, PSUs, locations, officials**; link to a controlled GoI **knowledge base/ontology**.
3. **Narrative & Sentiment:** Detect **stance** (supportive/critical/neutral), **sentiment**, **topics**, and **emerging themes**.
4. **Actionable Summaries:** Deliver **daily/weekly digests**, **live dashboards**, and **alerting** for anomalies/crises.
5. **True 360Â° Loop:** Capture **responses/clarifications** from departments and **citizen feedback**, measure **resolution** and **impact over time**.
6. **Privacy, Ethics, Compliance:** Respect Indian data laws, avoid PII leakage, maintain **audit trails** and **model cards**.

---

## ğŸŒ Multilingual Focus (Indic)

* **Languages (extensible):** Hindi, Bengali, Telugu, Marathi, Tamil, Gujarati, Kannada, Malayalam, Odia, Punjabi, Assamese, Urdu, etc.
* **Models (suggested options):**

  * **Tokenization/Embeddings:** MuRIL, IndicBERT, LaBSE, multilingual SBERT.
  * **NER:** Fineâ€‘tuned IndicBERT/MuRIL; Gazetteerâ€‘augmented for GoI entities.
  * **Sentiment/Stance:** Multilingual classifiers with domain fineâ€‘tuning; distant supervision via headlines; humanâ€‘inâ€‘theâ€‘loop corrections.
  * **Topic & Clustering:** BERTopic/Top2Vec with multilingual embeddings; online clustering for emerging issues.
  * **Summarization:** mT5/ByT5/Indicâ€‘friendly LLMs; length controls and safety filters.
  * **MT (optional):** Indicâ†”English translation for crossâ€‘lingual search & summaries.

> Choose models based on compute/security constraints; support CPUâ€‘first fallbacks and quantized variants.

---

## ğŸ§­ System Architecture

```mermaid
flowchart LR
  A[Source Ingestors\n(RSS, sitemaps, crawlers, APIs, TV/Radio transcripts)] --> B[Normalizer\n(clean, boilerplate removal, lang ID, dedupe)]
  B --> C[Classifier\n(GoI relevance, media type)]
  C --> D[Entity Layer\n(NER, entity linking to GoI KB)]
  D --> E[Narrative Layer\n(sentiment, stance, topic, clustering)]
  E --> F[Summarizer\n(abstracts, highlights, quotes)]
  F --> G[Store & Index\n(PostgreSQL + PGVector/Elastic)]
  G --> H[Dashboards & APIs\n(FastAPI, Streamlit/Next.js)]
  H --> I[Alerts\n(email/Teams/Slack/SMS)]
  H --> J[Feedback Capture\n(dept responses, citizen inputs)]
  J --> K[Humanâ€‘inâ€‘theâ€‘Loop Label Studio\n(active learning, QA)]
  K --> L[Model Training\n(offline retraining, eval, registry)]
  L --> C
```

---

## ğŸ§© Key Features

* **Source Ingestion**: Configurable crawlers for regional outlets; RSS/sitemaps; paywallâ€‘respecting integrations; optional YouTube/TV transcript fetchers where permitted.
* **Deâ€‘duplication**: Nearâ€‘duplicate detection using MinHash/SimHash + embedding cosine similarity.
* **Language Aware**: Automatic language ID, translation for crossâ€‘lingual search, nativeâ€‘language summaries on demand.
* **GoIâ€‘Aware NER & Linking**: Gazetteers + learned models; canonical IDs for ministries, schemes, officials, PSUs.
* **Narrative Intelligence**: Sentiment, stance, topics, emerging storyline detection; crisis spikes & velocity.
* **Summaries & Explainability**: Bullet summaries with extractive references; highlight key quotes; show evidence snippets.
* **Dashboards**: Geo maps by state/district; timeline trends; outletâ€‘wise stance heatmaps; entity coâ€‘occurrence.
* **360Â° Feedback Loop**: Intake forms/APIs for departments to respond; citizen input module; resolution tracking.
* **Governance**: Roleâ€‘based access; redaction; audit logs; model cards and drift monitoring.

---

## ğŸ› ï¸ Tech Stack (suggested)

* **Backend:** Python **FastAPI**, Celery workers, Redis (queues), PostgreSQL (+ **pgvector**) or Elasticsearch/OpenSearch.
* **Pipelines:** Airflow/Prefect or Kafka Streams for nearâ€‘realtime.
* **NLP/ML:** PyTorch, Hugging Face Transformers, sentenceâ€‘transformers, spaCy, BERTopic, scikitâ€‘learn, PyTorchâ€‘Lightning.
* **UI:** Next.js/React + Tailwind; alt: Streamlit for internal prototypes.
* **Deploy:** Docker Compose â†’ K8s (optional); Prometheus + Grafana; MLflow/Weights & Biases for experiments.

---

## ğŸ“¦ Repository Structure

```
.
â”œâ”€â”€ apps/
â”‚   â”œâ”€â”€ api/                # FastAPI app (ingest, search, analytics)
â”‚   â”œâ”€â”€ web/                # Next.js dashboard
â”‚   â””â”€â”€ worker/             # Celery/consumer jobs
â”œâ”€â”€ pipelines/              # Airflow/Prefect DAGs; Kafka consumers
â”œâ”€â”€ nlp/
â”‚   â”œâ”€â”€ models/             # training scripts, configs
â”‚   â”œâ”€â”€ gazetteers/         # GoI entities & synonyms
â”‚   â”œâ”€â”€ components/         # ner.py, sentiment.py, topic.py, summarizer.py
â”‚   â””â”€â”€ eval/               # evaluation datasets & notebooks
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ samples/            # redacted sample articles
â”‚   â””â”€â”€ schema/             # JSON schemas
â”œâ”€â”€ infra/                  # Docker, K8s, Terraform (if any)
â”œâ”€â”€ notebooks/              # exploration & reports
â”œâ”€â”€ tests/                  # unit/integration tests
â”œâ”€â”€ scripts/                # utilities (crawl, backfill, export)
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ .env.example
â””â”€â”€ README.md
```

---

## ğŸ” Compliance, Privacy & Ethics

* **Legal:** Respect terms of use for sources; avoid bypassing paywalls; comply with IT Act and relevant policies.
* **Privacy:** Store only required fields; redact PII; encrypt at rest and in transit; configurable retention.
* **Bias & Fairness:** Balanced training/eval sets by language & region; publish **model cards**; manual review for sensitive outputs.
* **Explainability:** Keep evidence snippets/URLs for each summary; show confidence scores.
* **Accessibility:** WCAGâ€‘compliant UI; multilingual content.

---

## ğŸ—‚ï¸ Data Model (simplified)

```json
Article {
  id: string,
  url: string,
  outlet: string,
  language: string,
  published_at: datetime,
  location: { state: string, district?: string },
  title: string,
  body: string,
  embeddings: vector,
  dedupe_key: string
}

StoryInsight {
  article_id: string,
  entities: [{ id: string, type: "ministry|scheme|official|psu|place", name: string }],
  sentiment: { label: "pos|neg|neu", score: float },
  stance: { label: "supportive|critical|neutral", score: float },
  topics: [string],
  summary: string,
  evidence: [{ text: string, start: int, end: int }]
}

Feedback {
  id: string,
  entity_id: string,
  source: "department|citizen|editor",
  message: string,
  created_at: datetime,
  resolution_status: "open|in_progress|resolved"
}
```

---

## ğŸ§ª Evaluation

* **NER:** F1 by entity type; exact/partial matches; KBâ€‘linking accuracy.
* **Sentiment/Stance:** Macroâ€‘F1; confusion matrices by language & outlet.
* **Summarization:** ROUGE, BERTScore, human eval for factuality & coverage.
* **Clustering/Topics:** Intrinsic coherence + human interpretability checks.
* **System:** Crawl coverage, deâ€‘dupe rate, latency, alert precision/recall.

---

## â–¶ï¸ Quick Start

### Prerequisites

* Python 3.10+
* Docker & Docker Compose
* PostgreSQL 14+ (or run via compose)

### Setup

```bash
# 1) Clone
git clone https://github.com/your-org/360-feedback-regional-media-goi.git
cd 360-feedback-regional-media-goi

# 2) Configure env
cp .env.example .env
# Fill database URLs, model paths, API keys for translation/ASR if used

# 3) Start services
docker compose up -d --build

# 4) Run migrations & seed GoI KB
make migrate
python scripts/seed_goi_kb.py data/seed/goi_entities.csv

# 5) Start workers and web
make worker
make api
make web
```

### Sample Requests

```bash
# Ingest an article (raw HTML or text)
curl -X POST http://localhost:8000/ingest \
  -H 'Content-Type: application/json' \
  -d '{
        "url": "https://example.com/news/kan-news-123",
        "html": "<html>â€¦</html>",
        "language": "kn"
      }'

# Search summaries for a scheme
curl 'http://localhost:8000/search?q=PM-KISAN&lang=en&since=2025-07-01'

# Get daily digest
curl 'http://localhost:8000/digest?date=2025-08-18&lang=en'
```

---

## ğŸ” 360Â° Feedback Loop

* **Department Portal:** View mentions, submit clarifications/responses.
* **Citizen Input:** Structured forms; optional verification (OTP/email).
* **Resolution Tracking:** Link department replies to stories; mark resolved; measure **timeâ€‘toâ€‘clarification** and **public reaction shift**.
* **Learning:** Approved edits feed back to training data via active learning.

---

## ğŸ§‘â€ğŸ’» Development

* **Code Style:** `ruff` + `black` + `mypy`.
* **Testing:** `pytest -q`; include fixture data per language.
* **CI/CD:** GitHub Actions for unit tests, container build, vulnerability scan.
* **Observability:** Structured logs (OpenTelemetry), request tracing, model latency metrics.

---

## ğŸ—ºï¸ Roadmap

* [ ] Expand gazetteers for schemes/PSUs & synonyms in 12+ languages
* [ ] Add streaming ASR for TV/radio clips (where licensed)
* [ ] Realâ€‘time crisis detection (spike + stance drift)
* [ ] Fineâ€‘tuned stance model per region/outlet
* [ ] Editor curation UI + human notes
* [ ] Redaction API + PII detector improvements
* [ ] Offline bundles for airâ€‘gapped deployments

---

## ğŸ¤ Contributing

Contributions are welcome! Please open an issue with context (language, outlet, feature). For major changes, discuss via an issue first.

---

## ğŸ“œ License

Choose a license that matches your deployment context (e.g., **Apacheâ€‘2.0** for permissive use). Update `LICENSE` accordingly.

---

## ğŸ™ Acknowledgements

Thanks to the openâ€‘source Indic NLP community and public datasets. Replace model/data references with the exact assets you adopt and credit appropriately.

---

## ğŸ“§ Contact

Project Maintainer: *Your Name* Â· *[email@example.com](mailto:email@example.com)*

> *Tip:* Open `issues/` for source suggestions (regional outlets), false positives, or feature requests.
